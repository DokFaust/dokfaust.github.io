---
layout: post
title: "A case study of multithread RNG in julia"
tags: [ gsoc, julia, RNG, report ]
---

# Background : The RNG issue

When using the `rand()` function in a multi-thread application,
 it is evident how the genrated numbers are not indipendent from each other,
 this can be followed from the [issue #10441](https://github.com/JuliaLang/julia/issues/10441).

As it is presented in the discussion, this can be tackled by providing a
different initialized state for each thread, so they can evolve independently from each other.

This still comes at a cost : it is crucial to understand that we are reasoning on a
peculiar situation, when RNG requires that we have, starting from a seed, a reproducible
sequence of numbers which are uncorrelated up to a lower-bounded Shannon Entropy.
On the other hand threads are scheduled in a way that is difficult to reconstruct, so
knowing at each time which resource was consumed by whom can be unfeasible.
This makes marging the two necessities a painful experience, so I will present in this post
some ways that I discussed with my mentors on how to handle it.

## First attempts and explorations

In general, when we have a global resource that is manipulated concurrently from different
threads, a general solution is to instatiate an array of  `n` copies of the aforementioned value,
where `n` is equal to the number of threads. The thread-specific variable is accessed in the array
according to the thread id. This approach has been tested on [issue #10441](https://github.com/JuliaLang/julia/issues/10441#issuecomment-375048552)
and it seems to give an appreciable slowdown of 10-25% on benchmarks.

Another option is the one presented in [KissThreading.jl](https://github.com/bkamins/KissThreading.jl/blob/master/src/KissThreading.jl#L5-L13) where each generator is instatiated using `randjump`,
that leaps forward a `MersenneTwister` state by a number of steps that are encoded in an argument
polynomial. This approach also seems not efficient on small-scale computations, where the global
state initialization can be crucial.

My first idea was to use `task_local_storage` as an alternative for native
TLS (thread-local storage) variables. A mixed approach between the two mentioned above could be
```
function GLOBAL_TRNG(rng = MersenneTwister(0), gpt = 1)
    n = Threads.nthreads()

    # Check if nthreads==1?
    rngjmp =  randjump(rng, big(10)^20, n * (gpt+1))
    threadRNG = reshape(rngjmp, (gpt+1,n))[1:gpt, :]
    Threads.@threads for i in 1:n
        task_local_storage()[:TRNG] = threadRNG[i]
    end

end

#Initialize thread-local RNG
GLOBAL_TRNG()

### Global RNG (must be defined after srand)
const GLOBAL_RNG = task_local_storage[:TRNG]
```
which also redefines the GLOBAL_RNG. The problem is that `task_local_storage()` can not be
regarded as an alternative for true TLS, as after initialization the defined TRNG goes out-of-scope.

## Industrial Espionage 101, or how others made it work.

As an example in Rust [`thread_rng`](https://docs.rs/rand/0.4.2/src/rand/lib.rs.html#879-893) is simply recollecting from the OS enough entropy to generate `n` random states
and instatiate them in a TLS array. The bottleneck cames from reading each time from an entropy source
(eg `/dev/urandom` in linux) which is too expensive.

What we can learn is that to instatiate a TLS array Rust uses a [key-value approach](https://doc.rust-lang.org/1.5.0/std/thread/struct.LocalKey.html), which is similar
to what we have seen in `task_local_storage`.
As the Julia threading library relies on __pthread__, it is interesting to see that it offers `pthread_setspecific` which associates with a key
a thread specific value. This can help us to model a Julia method to instatiate TLS states
```
/* threading.c */
// Other than setting the TLS value, we need the pthread key for future retrivial
pthread_key_t set_ptls(int size, (void*) value)
{
    static pthread_key_t kval;
    pthread_key_create(&kval, NULL);

    void* ptls = calloc(1, size);
    pthread_setspecific(kval, value);

    return kval;
}

/* threading.jl */
function dump_tsl(value::Any)
    size = sizeof(value)
    return ccall(:set_ptls, pthread_key_t, (Int64, Ptr{Void}), size, value)
end

#Define somewhere pthread_key_t

function retrieve_tls(key)
    return ccall(:pthread_getspecific, Ptr{Void}, (pthread_key_t,), key)
end

/* stdlib/Random/RNG.jl */

# Here we similarly to the code above, instatiate a TLS array, keep a trace
# of the key, and with randjump instatiate for each thread a RNG state.
# Calls to the GLOBAL_RNG are an alias for retrieve_tls(key)
```
### Issues : reproducibility and tasks

As for the current usage of __tasks__ it would be impossible for us to keep track
of which thread at a partcular point was executing a task.
This would undermine the possibility of proving backwards the validity of an RNG
result, and in general to backstep in number generation.

This may seem a silly issue, but considering that it would be impossible to prove that
at a particular execution point the produced number was the right one, given the number of steps,
can be a considerable roadblock in numeric applications, where Julia focuses.

For example this would made impossible to reproduce a posteriori the results of a Monte Carlo
simulation, which may be needed in some fields.

We decided that as a temporray solution we can ignore this issue.

## Future navigation roads

As the solution above seems a bit troublesome, especially when we have to figure out
how to manage a __pthread__ key in the Julia runtime, my mentor proposed another implementation.

As `MersenneTwister` currently instatiate a 2^64 state, and we can consider a max number of
threads in the order of 10^2, we could be able to define our seeded MT as a global RNG "buffer"
where each threads reads a slice.

Then using randjump we should be able for each thread to evolve each thread state independly,
maybe by writing a custom `srand()` method which reads the MT state according to the thread.

At that point we need to make sure that the state evolves a limited number of times (eg 10^5),
then each thread needs to read the MT state and re-evolve. This operation must be guarded by locks.

To conclude this doc, I confess that I have not a sketch ready for this.
